# 数据中台

以下内容为BLIBLI视频的笔记内容：[2小时快速入坑数据中台，完成数据中台体系搭建及技术选型！](https://www.bilibili.com/video/BV1MP4y1F7qE/?spm_id_from=333.337.search-card.all.click&vd_source=bd6f19b132dc159bf28e03fc5cce6e65)



## 课程技术栈

- Spark：Apache Spark 3.0.0
- Hadoop：2.6.0-cdh5.14.4
- MySQL：5.6+
- DataX：3.0
- Java：1.8.0
- Scala：2.12.10







![image-20230321175934222](https://p.ipic.vip/xe7vvc.png)

数据汇聚是数据中台必须提供的核心工具，将其内外部的各个系统数据汇聚实现集中存储。从物理上打破数据孤岛。



## 中台的前世今生

### 中台的缘起

中台进化：

1. 阶段1：烟囱式架构

   优点：

   ![image-20230322100014578](https://p.ipic.vip/t0yg6l.png)

   缺点：

   ![image-20230322100132946](https://p.ipic.vip/u4dece.png)

2. 阶段2：共性平台化架构

   优点：

   ![image-20230322100259660](https://p.ipic.vip/n3u8qu.png)

   缺点：

   ![image-20230322100407208](https://p.ipic.vip/pwqmfy.png)

   ![image-20230322100509460](https://p.ipic.vip/y9ua1x.png)

3. 阶段3：中台

   优点：

   ![image-20230322100543310](https://p.ipic.vip/r3w6dt.png)
   
   ![image-20230322101524157](https://p.ipic.vip/tmlhzp.png)

### 中台的演进

- 中台的演进过程
  
  ![image-20230322101828581](https://p.ipic.vip/f7x2t8.png)
  
  1. 业务中台
  
     *抽象业务流程的通用的业务能力。*
  
  2. 业务/数据双中台
  
     *打通各业务数据、汇聚多业务系统数据。*
  
  3. 更多细粒度的中台
  
     *更灵活地支撑更细粒度的业务线*
  
     *出现了：技术中台、算法中台、服务中台、安全中台等等各种各样的中台。整体的目标都是为了支撑更细粒度的业务线。*
  
- 数据中台和其它中台的关系
  
  - 数据中台是一切中台的基础
  
    ![image-20230322102051297](https://p.ipic.vip/z4qf7i.png)
  
  - 数据中台的应用闭环
  
    ![image-20230322102232522](https://p.ipic.vip/5wbzcw.png)
  
    业务应用是可以直接调用中台的数据

## 数据中台体系

![image-20230322135819697](https://p.ipic.vip/4g0cz8.png)

>  数据中台的建设的整体思路是基本一致的，比如像共享复用、提升开发效率、提供通用的组件工具以及快速形成服务的能力等等。

### 数据应用的发展阶段

![image-20230322135801480](https://p.ipic.vip/ef2pon.png)

1. 传统数据仓库EDW阶段
   - 定位：数据支持经营*决策*。
   
   - 数据形态：关系型数据为主，体量相对较小。
   
   - 关键技术：商业数据库，ETL/BI工具。
   
     *数据的架构一般是正向扩展的，机器配置不够就通过扩内存、扩CPU来提升单机的性能。这跟当前主流的横向扩展是有很多的区别的。横向扩展是通过扩节点增加机器来提升性能。传统的数据仓库这一阶段的技术就决定了横向扩展比较困能。企业往往通过购买大型机和小型机来提升单机的性能。*
   
   - 应用场景：BI报表工具、决策分析。
   
     *面向对象是企业的管理层来支撑他们的决策。*
   
2. 数据驱动的数据糊阶段
   - 定位：业务和数据深度融合。
   
   - 数据形态：数据形式多样、数据量大、数据标准化。
   
   - 关键技术：hadoop生态生态体系，机器学习/深度学习。
   
   - 应用场景：决策分析、针对性营销/推荐、用户画像。
   
     *除了支撑决策之外，用户画像、推荐系统也开始作为企业重要的应用，并且数据应用的实时性也得到的极大的提升。*


3. 数据中台阶段
   - 定位：企业级数据共享战略。
   
   - 数据形态：全域数据汇聚，体系化的数据资产。
   
     *随着业务的快速发展，数据量快速增长，因此要汇聚全域的数据，按照统一的标准对数据进行清洗加工形成体系化的资产数据，这样就能为数据应用提供标准化的数据能力。* 
   
   - 关键技术：平台化、通用工具、产品、统一数据服务体系。
   
   - 应用场景：决策分析、推荐、用户画像、OLTP实时交互。

### 成熟的数据中台具备能力

![image-20230322135917677](https://p.ipic.vip/yl2nfb.png)

> ​    如果将数据中台比作饭店，那么数据中台就是一个提供数据服务的场所，数据就是食材，数据服务就是菜品。数据中台需要提供各种各样的数据服务，就像饭店需要提供各种各样的菜品一样。数据中台需要提供数据的存储、计算、分析、挖掘、可视化等服务，这些服务就像饭店需要提供烹饪、调味、摆盘、服务等环节一样。数据中台需要提供高质量的数据服务，就像饭店需要提供美味可口的菜品一样。因此，数据中台需要不断地提高数据服务的质量和效率，以满足用户的需求。

![image-20230322131127032](https://p.ipic.vip/5n6sgs.png)

- 汇聚全域数据（采购食材）

- 构建统一的数据资产体系能力（洗、切）

- 完善的数据资产管理能力（菜品/菜谱、质量）

- 工具/组件平台化（打蛋器等机械设备）

   *这些设备就对应于数据中台的工具和组件，例：使用Spark Streaming消费Kafka的数据时，通常是需要对Topic的Offset进行手工的管理，有些业务存储在MySQL中，有的业务是保存在Hbase中，因此我们可以将Offset的存储封装成SDK的组件来支持将Offset持久到不通存储库中。*

- 流程可视化

   *一个好用的产品应该是基于可视化的操作界面，比如数据处理可视化、元数据管理可视化、数据分析可视化、数据资产目录可视化等等。有了可视化的操作界面就可以让使用人员快速上手，屏蔽底层复杂的技术组件，降低使用成本。*

- 系统架构与组织架构匹配（工种）

  

### 数据中台架构

![image-20230322135939262](https://p.ipic.vip/yfy6x7.png)



![image-20230321174046672](https://p.ipic.vip/5gq3t3.png)

1. 数据资源

   >  企业内部或外部未经加过的数据。

   - RDBPM
   - NoSQL
   - 消息队列
   - 文件系统
   - 数据服务的数据

2. 计算存储

   >  是数据中台的核心组件，数据的计算和存储都是在这层中完成的。

   - HDFS
   - Kafka
   - MPP
   - Spark
   - Flink

3. 数据汇聚

   >  由于企业数据的多样性，数据是存储在不同的网络，不同的数据库甚至不通的形式，数据难以整合来难以体验数据的价值。而数据汇聚就是将各种异构的数据源通过离线或者实时的方式采集至数据中台进行集中存储，从物理上打破数据孤岛，为了屏蔽底层复杂组件数据汇聚应该具备提供可视化的配置管理页面。

   - 异构数据源
   - 离线/实时
   - 配置管理

4. 数据资产

   > 数据资产是建设数据中台的核心内容，数据资产更容易被数据应用获取，也能更好的支撑数据的应用。包括数据的模型、架构的设计以及主题域的设计。
   >
   > 数据的模型架构设计一般是采用分层的设计思路。

   - ODS（原始数据层）：尽可能保留与原始业务数据一致。 
   - 公共明细层DWD：
   - 公共汇总层DWS：是数据资产的主体内容，一般是采用纬度建模的方式进行设计。这两层的数据是通过ODS层的数据清洗加工转换生成的。
   - ADS（应用层）：各个业务线基于公共明细层和公共汇总层建立起来的。 
   - 标签数据
   - 应用数据

5. 数据服务

   >  数据服务层使用数据资产层的数据来发挥数据的价值。

   - API服务
   - 鉴权管理
   - 即席查询
   - 在线查询

6. 资产管理

   > 资产管理的目的是为了保证数据的质量，提升数据的易用性，实现数据的增值。通过资产管理能让使用者能够清晰的了解企业数据的资产情况，快速的实现资产的查看、管理的功能。
   >
   > 作为一个成熟的数据中台的架构，应当能够以可视化的方式来直观的管理和展示数据资产。

   - 元数据管理
   - 数据血缘
   - 数据质量
   - 生命周期
   - 资产目录管理

7. 数据运营管理

8. 数据安全管理

   >  这两个模块保证数据中台健康稳定运行，持续产生价值的保证。

9. 数据开发管理

   > 始终提供各类数据处理的套件和工具。

   - 数据同步套件：在各种组件之间进行数据的交换，包括数据的读取、转换和写入。

     *包括数据的读取、写入和转换*

   - SDK套件

   - 数据开发套件：对数据的处理程序进行封装，如离线的开发套件使用SparkSQL作为底层的引擎进行封装，开发人员只需要Web页面编写SQL代码并进行简单的配置就可以完成数据的处理。

   - 调度管理：管理数据开发任务之间的依赖问题。

   - 小文件合并：一些合并的工具。

10. 数据应用

    > 各类数据的应用，数据资产层进行各种计算所产生的结果通过各种途径输送至业务的场景中。

    - BI分析
    - 用户画像
    - 推荐系统
    - 业务中台



### 技术选型

![image-20230322140018431](https://p.ipic.vip/945s1r.png)

![image-20230322134811069](https://p.ipic.vip/iejqtv.png)

- 数据采集汇聚

  - 日志实时采集：Filebeat、Flume等。
  - 数据库实时同步：MaxWell、cancel、OGG。
  - 离线数据交换：Sqoop、DataX、自研产品。

- 数据存储

  - Hadoop分布式文件系统HDFS。
  - 流式数据总线的消息队列Kafka。
  - 海量数据随机查询Hbase/Phoenix。
  - 搜索引擎Elasticsearch。
  - MPP数据库Clickhouse。

- 计算引擎

  - 离线计算：Spark、Hive

    *一般不会直接使用Hive做离线的计算，而是结合Spark计算能力加上Hive的Metadata对数据进行管理，例如我们可以使用Spark将数据写入HDFS目录，那这个目录可以是Hive的表内部或者外部文件的路径，这样就建立了文件和表的关联。*

  - 实时计算：Spark Streaming、Structured Streaming、Flink

- 即席查询

  - ROLAP（Relational OLAP）：Presto、ClickHouse、Doris
  - MOLAP（Multidimensional OLAP）：Kylin、Druid

- 在线查询

  ![image-20230322135420302](https://p.ipic.vip/2xqd4o.png)

  - 延迟响应要求高：Redis
  - 延迟响应要求正常：Mysql、TIDB、Hbase
  - 检索场景：Elasticsearch

- 数据调度

  AzKaban、Airflow、DolphinScheduler

## 基于Spark的多源异构数据同步套件

![image-20230322140305631](https://p.ipic.vip/81k3f5.png)

-  数据采集、汇聚的技术架构
  - 数据采集内容和方式
  
    ![image-20230322141014589](https://p.ipic.vip/em9avy.png)
  
  - 实时/离线同步流程
  
    ![image-20230322141246469](https://p.ipic.vip/l8624c.png)
  
    ![image-20230322141311199](https://p.ipic.vip/5jrvof.png)
  
    
  
- 构建异构数据源的同步套件
  
  
  
  - 当前工具和方法存储的问题
    - 开源工具问题分析
    
      ![image-20230322141750944](https://p.ipic.vip/wkiu2h.png)
    
    - 定制程序问题分析
    
      ![image-20230322141856128](https://p.ipic.vip/4w55jf.png)
    
  - 异构数据同步套件具备的功能
  
    ![image-20230322141918676](https://p.ipic.vip/l1o8fl.png)
  
    ![image-20230322142035910](https://p.ipic.vip/unktsp.png)

- 移植DataX的配置管理功能

  ![image-20230322142145007](https://p.ipic.vip/gnrsjw.png)

  - DataX数据同步案例

    基于Reader、Transformer和Writer模块，同步MySQL表至HDFS

    ![image-20230322142226836](https://p.ipic.vip/yqqtbj.png)
  
    
  
  - 移植DataX配置管理功能方式
  
    - 方式一：摘取DataX配置管理相关的源码
    - 方式二：datax-common-0.0.1-SNAPSHOT.java
  
  - 配置管理的功能点及代码示例
  
    ![image-20230322144439496](https://p.ipic.vip/a0pw8f.png)
    
    - 获取基本数据类型
    - 获取Config对象
    - 获取Config对象列表
    - 获取Map集合
    - 获取列表
    - 多个配置合并



- 关系型数据库同步至HDFS的通用套件

  ![image-20230322145359023](https://p.ipic.vip/irq0t3.png)

  

  - 需求

    基于配置，零代码开发，实现关系型数据库（MySQL/Oracle等）的表数据同步至HDFS，数据转换模块的插件化管理。
  
  - 实现过程
  
    1. 阶段1：关系型数据库同步至HDFS的功能开发，以硬编码方式。
    2. 阶段2：仿照DataX的运行模型，将同步流程抽象为Reader、Transformer和Writer模块。
    3. 阶段3：数据转换的插件化改造，功能扩展时（例如需求变更）无需修改代码。

- 基于Spark的数据同步套件设计思路
  - 基本的数据同步套件
  - 多数据源的数据同步套件
